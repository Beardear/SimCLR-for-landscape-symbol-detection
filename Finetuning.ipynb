{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad91fa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0c41591",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"./Firefighting Device Detection.v6i.yolov11/train/images\"\n",
    "input_label = \"./Firefighting Device Detection.v6i.yolov11/train/labels\"\n",
    "output_dir = \"./dataset_crops\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "362b4944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_and_save_symbols():\n",
    "    os.makedirs(output_dir, exist_ok = True)\n",
    "    # load path\n",
    "    label_files = glob.glob(os.path.join(input_label, \"*.txt\"))\n",
    "\n",
    "    crop_count = 0\n",
    "    print(f\"Found {len(label_files)} label files. Starting extraction...\")\n",
    "\n",
    "    for label_path in tqdm(label_files):\n",
    "        base_name = os.path.basename(label_path).replace(\".txt\", \"\")\n",
    "        img_path = os.path.join(input_dir, base_name + \".jpg\")\n",
    "    \n",
    "        # load images\n",
    "        image = cv2.imread(img_path)\n",
    "        \n",
    "        h_img, w_img, _ = image.shape\n",
    "\n",
    "        # read annotations (YOLO11 format)\n",
    "        with open(label_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "\n",
    "        for line in lines:\n",
    "            parts = line.strip().split()\n",
    "            cls_id = parts[0]\n",
    "\n",
    "            x_c, y_c, w_norm, h_norm = map(float, parts[1:])\n",
    "\n",
    "            w_px = int(w_norm * w_img)\n",
    "            h_px = int(h_norm * h_img)\n",
    "            x_px = int((x_c * w_img) - (w_px // 2))\n",
    "            y_px = int((y_c * h_img) - (h_px //2))\n",
    "\n",
    "            # clamp to the image boundaries\n",
    "            x_px = max(0, x_px)\n",
    "            y_px = max(0, y_px)\n",
    "            w_px = min(w_px, w_img - x_px)\n",
    "            h_px = min(h_px, h_img - y_px)\n",
    "\n",
    "            # crop_and_save_symbols\n",
    "            crop = image[y_px:y_px+h_px, x_px:x_px + w_px]\n",
    "\n",
    "            save_name = os.path.join(output_dir, f\"symbol_{crop_count}.jpg\")\n",
    "            cv2.imwrite(save_name, crop)\n",
    "            crop_count += 1\n",
    "            \n",
    "    print(\"cropping is done!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a69e174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 102 label files. Starting extraction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [00:02<00:00, 41.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cropping is done!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "crop_and_save_symbols()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad559be",
   "metadata": {},
   "source": [
    "## train Simclr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee754c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "852f8ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af1971a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Number of available GPUs: 3\n",
      "Current GPU device name: NVIDIA RTX A6000\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 128    # Needs to be large for Contrastive Learning\n",
    "EPOCHS = 1000\n",
    "LR = 3e-4\n",
    "TEMP = 0.07         # Temperature parameter for NCE loss\n",
    "EMBED_DIM = 128\n",
    "DATA_DIR = \"./dataset_crops\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"Using device: {device}\")\n",
    "    print(f\"Number of available GPUs: {torch.cuda.device_count()}\")\n",
    "    print(f\"Current GPU device name: {torch.cuda.get_device_name(0)}\") # Prints name of the first GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86e0de78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training on cuda with 2606 symbols...\n",
      "Epoch [1/200] Loss: 4.8320\n",
      "Epoch [2/200] Loss: 4.4206\n",
      "Epoch [3/200] Loss: 4.1692\n",
      "Epoch [4/200] Loss: 3.8943\n",
      "Epoch [5/200] Loss: 3.7196\n",
      "Epoch [6/200] Loss: 3.6006\n",
      "Epoch [7/200] Loss: 3.5529\n",
      "Epoch [8/200] Loss: 3.4788\n",
      "Epoch [9/200] Loss: 3.4518\n",
      "Epoch [10/200] Loss: 3.4398\n",
      "Saved Backbone Checkpoint at epoch 10\n",
      "Epoch [11/200] Loss: 3.3460\n",
      "Epoch [12/200] Loss: 3.2232\n",
      "Epoch [13/200] Loss: 3.2048\n",
      "Epoch [14/200] Loss: 3.1656\n",
      "Epoch [15/200] Loss: 3.1388\n",
      "Epoch [16/200] Loss: 3.1336\n",
      "Epoch [17/200] Loss: 3.0739\n",
      "Epoch [18/200] Loss: 3.0628\n",
      "Epoch [19/200] Loss: 3.0336\n",
      "Epoch [20/200] Loss: 2.9989\n",
      "Saved Backbone Checkpoint at epoch 20\n",
      "Epoch [21/200] Loss: 2.9831\n",
      "Epoch [22/200] Loss: 2.9995\n",
      "Epoch [23/200] Loss: 2.9303\n",
      "Epoch [24/200] Loss: 2.9135\n",
      "Epoch [25/200] Loss: 2.8846\n",
      "Epoch [26/200] Loss: 2.8592\n",
      "Epoch [27/200] Loss: 2.8983\n",
      "Epoch [28/200] Loss: 2.8701\n",
      "Epoch [29/200] Loss: 2.7976\n",
      "Epoch [30/200] Loss: 2.8363\n",
      "Saved Backbone Checkpoint at epoch 30\n",
      "Epoch [31/200] Loss: 2.7659\n",
      "Epoch [32/200] Loss: 2.7944\n",
      "Epoch [33/200] Loss: 2.7440\n",
      "Epoch [34/200] Loss: 2.7384\n",
      "Epoch [35/200] Loss: 2.7421\n",
      "Epoch [36/200] Loss: 2.7008\n",
      "Epoch [37/200] Loss: 2.7002\n",
      "Epoch [38/200] Loss: 2.6842\n",
      "Epoch [39/200] Loss: 2.6971\n",
      "Epoch [40/200] Loss: 2.6504\n",
      "Saved Backbone Checkpoint at epoch 40\n",
      "Epoch [41/200] Loss: 2.6135\n",
      "Epoch [42/200] Loss: 2.6306\n",
      "Epoch [43/200] Loss: 2.5952\n",
      "Epoch [44/200] Loss: 2.6285\n",
      "Epoch [45/200] Loss: 2.5805\n",
      "Epoch [46/200] Loss: 2.6102\n",
      "Epoch [47/200] Loss: 2.5088\n",
      "Epoch [48/200] Loss: 2.5406\n",
      "Epoch [49/200] Loss: 2.5760\n",
      "Epoch [50/200] Loss: 2.5404\n",
      "Saved Backbone Checkpoint at epoch 50\n",
      "Epoch [51/200] Loss: 2.5377\n",
      "Epoch [52/200] Loss: 2.5580\n",
      "Epoch [53/200] Loss: 2.5332\n",
      "Epoch [54/200] Loss: 2.4608\n",
      "Epoch [55/200] Loss: 2.4877\n",
      "Epoch [56/200] Loss: 2.4741\n",
      "Epoch [57/200] Loss: 2.4748\n",
      "Epoch [58/200] Loss: 2.4296\n",
      "Epoch [59/200] Loss: 2.4497\n",
      "Epoch [60/200] Loss: 2.3862\n",
      "Saved Backbone Checkpoint at epoch 60\n",
      "Epoch [61/200] Loss: 2.4978\n",
      "Epoch [62/200] Loss: 2.4212\n",
      "Epoch [63/200] Loss: 2.3916\n",
      "Epoch [64/200] Loss: 2.4132\n",
      "Epoch [65/200] Loss: 2.4129\n",
      "Epoch [66/200] Loss: 2.4252\n",
      "Epoch [67/200] Loss: 2.3478\n",
      "Epoch [68/200] Loss: 2.3759\n",
      "Epoch [69/200] Loss: 2.3655\n",
      "Epoch [70/200] Loss: 2.4134\n",
      "Saved Backbone Checkpoint at epoch 70\n",
      "Epoch [71/200] Loss: 2.3599\n",
      "Epoch [72/200] Loss: 2.3826\n",
      "Epoch [73/200] Loss: 2.3095\n",
      "Epoch [74/200] Loss: 2.3488\n",
      "Epoch [75/200] Loss: 2.3297\n",
      "Epoch [76/200] Loss: 2.3392\n",
      "Epoch [77/200] Loss: 2.3212\n",
      "Epoch [78/200] Loss: 2.3154\n",
      "Epoch [79/200] Loss: 2.2759\n",
      "Epoch [80/200] Loss: 2.3345\n",
      "Saved Backbone Checkpoint at epoch 80\n",
      "Epoch [81/200] Loss: 2.3322\n",
      "Epoch [82/200] Loss: 2.2959\n",
      "Epoch [83/200] Loss: 2.2815\n",
      "Epoch [84/200] Loss: 2.2515\n",
      "Epoch [85/200] Loss: 2.2737\n",
      "Epoch [86/200] Loss: 2.2783\n",
      "Epoch [87/200] Loss: 2.2612\n",
      "Epoch [88/200] Loss: 2.2424\n",
      "Epoch [89/200] Loss: 2.2587\n",
      "Epoch [90/200] Loss: 2.2064\n",
      "Saved Backbone Checkpoint at epoch 90\n",
      "Epoch [91/200] Loss: 2.2275\n",
      "Epoch [92/200] Loss: 2.2422\n",
      "Epoch [93/200] Loss: 2.2024\n",
      "Epoch [94/200] Loss: 2.2224\n",
      "Epoch [95/200] Loss: 2.1552\n",
      "Epoch [96/200] Loss: 2.1850\n",
      "Epoch [97/200] Loss: 2.1324\n",
      "Epoch [98/200] Loss: 2.2153\n",
      "Epoch [99/200] Loss: 2.1880\n",
      "Epoch [100/200] Loss: 2.1789\n",
      "Saved Backbone Checkpoint at epoch 100\n",
      "Epoch [101/200] Loss: 2.2032\n",
      "Epoch [102/200] Loss: 2.1881\n",
      "Epoch [103/200] Loss: 2.1668\n",
      "Epoch [104/200] Loss: 2.1539\n",
      "Epoch [105/200] Loss: 2.0885\n",
      "Epoch [106/200] Loss: 2.1455\n",
      "Epoch [107/200] Loss: 2.1284\n",
      "Epoch [108/200] Loss: 2.1477\n",
      "Epoch [109/200] Loss: 2.1029\n",
      "Epoch [110/200] Loss: 2.1349\n",
      "Saved Backbone Checkpoint at epoch 110\n",
      "Epoch [111/200] Loss: 2.1238\n",
      "Epoch [112/200] Loss: 2.0679\n",
      "Epoch [113/200] Loss: 2.1129\n",
      "Epoch [114/200] Loss: 2.0715\n",
      "Epoch [115/200] Loss: 2.0866\n",
      "Epoch [116/200] Loss: 2.0906\n",
      "Epoch [117/200] Loss: 2.0546\n",
      "Epoch [118/200] Loss: 2.0707\n",
      "Epoch [119/200] Loss: 2.0549\n",
      "Epoch [120/200] Loss: 2.0484\n",
      "Saved Backbone Checkpoint at epoch 120\n",
      "Epoch [121/200] Loss: 2.0745\n",
      "Epoch [122/200] Loss: 2.0486\n",
      "Epoch [123/200] Loss: 1.9893\n",
      "Epoch [124/200] Loss: 2.0314\n",
      "Epoch [125/200] Loss: 2.0156\n",
      "Epoch [126/200] Loss: 1.9529\n",
      "Epoch [127/200] Loss: 2.0359\n",
      "Epoch [128/200] Loss: 1.9912\n",
      "Epoch [129/200] Loss: 1.9857\n",
      "Epoch [130/200] Loss: 2.0118\n",
      "Saved Backbone Checkpoint at epoch 130\n",
      "Epoch [131/200] Loss: 1.9963\n",
      "Epoch [132/200] Loss: 1.9528\n",
      "Epoch [133/200] Loss: 1.9398\n",
      "Epoch [134/200] Loss: 1.9675\n",
      "Epoch [135/200] Loss: 1.9636\n",
      "Epoch [136/200] Loss: 1.9529\n",
      "Epoch [137/200] Loss: 1.9290\n",
      "Epoch [138/200] Loss: 1.9798\n",
      "Epoch [139/200] Loss: 1.9140\n",
      "Epoch [140/200] Loss: 1.9857\n",
      "Saved Backbone Checkpoint at epoch 140\n",
      "Epoch [141/200] Loss: 1.9524\n",
      "Epoch [142/200] Loss: 1.9019\n",
      "Epoch [143/200] Loss: 1.8964\n",
      "Epoch [144/200] Loss: 1.8894\n",
      "Epoch [145/200] Loss: 1.9028\n",
      "Epoch [146/200] Loss: 1.8694\n",
      "Epoch [147/200] Loss: 1.9288\n",
      "Epoch [148/200] Loss: 1.8806\n",
      "Epoch [149/200] Loss: 1.8857\n",
      "Epoch [150/200] Loss: 1.8960\n",
      "Saved Backbone Checkpoint at epoch 150\n",
      "Epoch [151/200] Loss: 1.9124\n",
      "Epoch [152/200] Loss: 1.9084\n",
      "Epoch [153/200] Loss: 1.8771\n",
      "Epoch [154/200] Loss: 1.8427\n",
      "Epoch [155/200] Loss: 1.8411\n",
      "Epoch [156/200] Loss: 1.8157\n",
      "Epoch [157/200] Loss: 1.7739\n",
      "Epoch [158/200] Loss: 1.8491\n",
      "Epoch [159/200] Loss: 1.8667\n",
      "Epoch [160/200] Loss: 1.7713\n",
      "Saved Backbone Checkpoint at epoch 160\n",
      "Epoch [161/200] Loss: 1.7771\n",
      "Epoch [162/200] Loss: 1.8078\n",
      "Epoch [163/200] Loss: 1.7887\n",
      "Epoch [164/200] Loss: 1.7914\n",
      "Epoch [165/200] Loss: 1.8298\n",
      "Epoch [166/200] Loss: 1.7733\n",
      "Epoch [167/200] Loss: 1.8259\n",
      "Epoch [168/200] Loss: 1.7499\n",
      "Epoch [169/200] Loss: 1.7443\n",
      "Epoch [170/200] Loss: 1.7746\n",
      "Saved Backbone Checkpoint at epoch 170\n",
      "Epoch [171/200] Loss: 1.7769\n",
      "Epoch [172/200] Loss: 1.7730\n",
      "Epoch [173/200] Loss: 1.7460\n",
      "Epoch [174/200] Loss: 1.7543\n",
      "Epoch [175/200] Loss: 1.7472\n",
      "Epoch [176/200] Loss: 1.7188\n",
      "Epoch [177/200] Loss: 1.7137\n",
      "Epoch [178/200] Loss: 1.6659\n",
      "Epoch [179/200] Loss: 1.7197\n",
      "Epoch [180/200] Loss: 1.7613\n",
      "Saved Backbone Checkpoint at epoch 180\n",
      "Epoch [181/200] Loss: 1.6464\n",
      "Epoch [182/200] Loss: 1.6882\n",
      "Epoch [183/200] Loss: 1.7250\n",
      "Epoch [184/200] Loss: 1.7347\n",
      "Epoch [185/200] Loss: 1.7580\n",
      "Epoch [186/200] Loss: 1.6865\n",
      "Epoch [187/200] Loss: 1.6728\n",
      "Epoch [188/200] Loss: 1.6598\n",
      "Epoch [189/200] Loss: 1.6580\n",
      "Epoch [190/200] Loss: 1.6422\n",
      "Saved Backbone Checkpoint at epoch 190\n",
      "Epoch [191/200] Loss: 1.6853\n",
      "Epoch [192/200] Loss: 1.6269\n",
      "Epoch [193/200] Loss: 1.6402\n",
      "Epoch [194/200] Loss: 1.6632\n",
      "Epoch [195/200] Loss: 1.6085\n",
      "Epoch [196/200] Loss: 1.6618\n",
      "Epoch [197/200] Loss: 1.6529\n",
      "Epoch [198/200] Loss: 1.6195\n",
      "Epoch [199/200] Loss: 1.6080\n",
      "Epoch [200/200] Loss: 1.5756\n",
      "Saved Backbone Checkpoint at epoch 200\n",
      "List saved to loss.npy\n",
      "Plot saved to plot_output.png\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAQDNJREFUeJzt3X98k/W9//9nWkoKpQ0ULAnyqwoDawEtG1DZ1CFokaFuO+c4Bgd1yiaDfXBu+3DYZw7Qc1Ydt415Djv4a8q2ip6jExhOcSAiBynyo3CkMFH4lh9KAoPatBTaQnN9/6CJTZu0SZvkapLH/XbLbebKleR9LcL19P3j9bYYhmEIAADAJClmNwAAACQ3wggAADAVYQQAAJiKMAIAAExFGAEAAKYijAAAAFMRRgAAgKkIIwAAwFTdzG5AKDwej06ePKnMzExZLBazmwMAAEJgGIZqamo0YMAApaQE7/+IizBy8uRJDRo0yOxmAACADjhx4oQGDhwY9PW4CCOZmZmSLl9MVlaWya0BAAChqK6u1qBBg3z38WDiIox4h2aysrIIIwAAxJn2plgwgRUAAJiKMAIAAExFGAEAAKYijAAAAFMRRgAAgKkIIwAAwFSEEQAAYCrCCAAAMFVcFD2LhkaPoZ0VlTpdU6eczHSNy81Wagr73gAAEGtJGUY2lDu1dP1BOd11vmMOW7oWT89TUb7DxJYBAJB8km6YZkO5U3NLyvyCiCS53HWaW1KmDeVOk1oGAEBySqow0ugxtHT9QRkBXvMeW7r+oBo9gc4AAADRkFRhZGdFZasekeYMSU53nXZWVMauUQAAJLmkCiOna4IHkY6cBwAAOi+pwkhOZnpEzwMAAJ2XVGFkXG62HLZ0BVvAa9HlVTXjcrNj2SwAAJJaUoWR1BSLFk/Pk6RWgcT7fPH0POqNAAAQQ0kVRiSpKN+hlbMKZLf5D8XYbelaOauAOiMAAMRY0oUR6XIg2bZwkr5+/QBJ0q15/bVt4SSCCAAAJkjKMCJdHrIZac+SJPWydmNoBgAAkyRtGJGkXumXq+HX1F8yuSUAACSv5A4j1sthpJYwAgCAaQgjks4RRgAAMA1hRNK5OsIIAABmSe4wkk7PCAAAZkvuMMIwDQAApiOMSDrf0KhGj2FyawAASE7JHUaahmkkqbaB3hEAAMyQ1GHE2i1VaamXi50xiRUAAHMkdRiRmDcCAIDZCCOsqAEAwFRJH0YyulNrBAAAMyV9GMmkZwQAAFMlfRhhzggAAOZK+jCSQUl4AABMlfRhhGEaAADMlfRhxDtMU0sYAQDAFEkfRrzDNDWEEQAATJH0YaQXc0YAADBV0ocR75wRhmkAADBH0ocRhmkAADBX0ocRhmkAADBX0ocR3zBNA2EEAAAzJH0YoegZAADm6lQYefzxx2WxWPTQQw8FPWfVqlWyWCx+j/T09M58bUT1Ys4IAACm6tbRN+7atUtPP/20Ro8e3e65WVlZOnTokO+5xWLp6NdGXKY1TZLUcMmjhksede+W9J1FAADEVIfuvOfOndPMmTP17LPPqk+fPu2eb7FYZLfbfY/+/ft35GujIsOa6vtnlvcCABB7HQoj8+bN07Rp0zR58uSQzj937pyGDBmiQYMG6c4779SBAwfaPL++vl7V1dV+j2jplpqi9LTL/zewPw0AALEXdhh5+eWXVVZWpuLi4pDOHzFihJ5//nmtW7dOJSUl8ng8uuGGG/TJJ58EfU9xcbFsNpvvMWjQoHCbGZZeTUM1hBEAAGIvrDBy4sQJLViwQC+++GLIk1ALCws1e/ZsXXfddbrpppv02muv6YorrtDTTz8d9D2LFi2S2+32PU6cOBFOM8PWq2mohjACAEDshTWBdc+ePTp9+rQKCgp8xxobG7V161atWLFC9fX1Sk1NbeMTpLS0NF1//fU6fPhw0HOsVqusVms4TeuUXk21RggjAADEXlhh5JZbbtH+/fv9jt13330aOXKkFi5c2G4QkS6Hl/379+v2228Pr6VRlNH9cru3fHha6d1SNS43W6kpXWfFDwAAiSysMJKZman8/Hy/YxkZGerbt6/v+OzZs3XllVf65pQ8+uijmjBhgoYNG6aqqiotW7ZMx44d0wMPPBChS+icDeVO7TvhliT9vvSYfl96TA5buhZPz1NRvsPk1gEAkPgiXlTj+PHjcjqdvuefffaZ5syZo2uuuUa33367qqurtX37duXl5UX6q8O2odypuSVlqr/k8TvuctdpbkmZNpQ7g7wTAABEisUwDMPsRrSnurpaNptNbrdbWVlZEfnMRo+hLz+xWU53XcDXLZLstnRtWziJIRsAADog1Pt30pYb3VlRGTSISJIhyemu086Kytg1CgCAJJS0YeR0TfAg0pHzAABAxyRtGMnJDK1OSqjnAQCAjknaMDIuN1sOW7qCzQaxSHLY0jUuNzuWzQIAIOkkbRhJTbFo8fTAK3q8AWXx9DwmrwIAEGVJG0YkqSjfoZWzCpST6V/t1W5L18pZBdQZAQAgBsIqepaIivId+srwK3Tt4rckSc/N/qK+OjKHHhEAAGIkqXtGvDKs3ZTZtD9N7hUZBBEAAGKIMNKkX6/LQzVnzzWY3BIAAJILYaRJ34zukqQz5+pNbgkAAMmFMNLk854RwggAALFEGGnSt5e3Z4RhGgAAYokw0qRvU88IwzQAAMQWYaTJFU09I0xgBQAgtggjTbw9I2dr6RkBACCWCCNNPl9NQ88IAACxRBhp0i+TOSMAAJiBMNKkX8blMFJTd0n1lxpNbg0AAMmDMNIkq0c3paVeLgPPJFYAAGKHMNLEYrGobwYl4QEAiDXCSDO+wmesqAEAIGYII834Cp/VEEYAAIgVwkgzfTPSJEn/8/EZlR45q0aPYXKLAABIfN3MbkBXsaHcqb8eOCVJ+vP/ntSf//ekHLZ0LZ6ep6J8h8mtAwAgcdEzostBZG5JmWob/Jf0utx1mltSpg3lTpNaBgBA4kv6MNLoMbR0/UEFGpDxHlu6/iBDNgAAREnSh5GdFZVyuuuCvm5IcrrrtLOiMnaNAgAgiSR9GDldEzyIdOQ8AAAQnqQPIzmZ6RE9DwAAhCfpw8i43Gw5bOmyBHndIslhS9e43OxYNgsAgKSR9GEkNcWixdPzJKlVIPE+Xzw9T6kpweIKAADojKQPI5JUlO/QylkFstv8h2LstnStnFVAnREAAKKIomdNivIdmpJn1+Rfv6uKM7X6v7d9Qd+7aRg9IgAARBk9I82kplg0KLunJCknqwdBBACAGCCMtNA34/LOvZXs3AsAQEwQRlro09MbRi6a3BIAAJIDYaSF7Kade+kZAQAgNggjLWRnWCXRMwIAQKwQRlqgZwQAgNgijLTg7Rn57Dw9IwAAxEKnwsjjjz8ui8Wihx56qM3zXnnlFY0cOVLp6ekaNWqU3njjjc58bVR93jPSYHJLAABIDh0OI7t27dLTTz+t0aNHt3ne9u3bNWPGDN1///3au3ev7rrrLt11110qLy/v6FdHlbdnxH3hoi42ekxuDQAAia9DYeTcuXOaOXOmnn32WfXp06fNc5988kkVFRXpJz/5ia655ho99thjKigo0IoVKzrU4Giz9UiTpanWWRVDNQAARF2Hwsi8efM0bdo0TZ48ud1zS0tLW5132223qbS0NOh76uvrVV1d7feIldQUi3r3YKgGAIBYCXtvmpdfflllZWXatWtXSOe7XC7179/f71j//v3lcrmCvqe4uFhLly4Nt2kRk53RXZ+dv0gYAQAgBsLqGTlx4oQWLFigF198Uenp6e2/oYMWLVokt9vte5w4cSJq3xVItq8kPGEEAIBoC6tnZM+ePTp9+rQKCgp8xxobG7V161atWLFC9fX1Sk1N9XuP3W7XqVOn/I6dOnVKdrs96PdYrVZZrdZwmhZRvjBynjACAEC0hdUzcsstt2j//v3at2+f7/HFL35RM2fO1L59+1oFEUkqLCzU22+/7Xds48aNKiws7FzLo8gXRs4RRgAAiLawekYyMzOVn5/vdywjI0N9+/b1HZ89e7auvPJKFRcXS5IWLFigm266Sb/61a80bdo0vfzyy9q9e7eeeeaZCF1C5HnDyGf0jAAAEHURr8B6/PhxOZ1O3/MbbrhBq1ev1jPPPKMxY8bo1Vdf1dq1a1uFmq7Eu3PvWeaMAAAQdRbDMAyzG9Ge6upq2Ww2ud1uZWVlRf37Xt19Qj9+9QON6J+pJXdcq3G52UpNsUT9ewEASCSh3r/Zm6aFDeVO/dsbf5MkHTpVoxnP7tCXn9isDeXOdt4JAAA6gjDSzIZyp+aWlLXaJM/lrtPckjICCQAAUUAYadLoMbR0/UEFGrPyHlu6/qAaPV1+VAsAgLhCGGmys6JSTndd0NcNSU53nXZWVMauUQAAJAHCSJPTNcGDSEfOAwAAoSGMNMnJDK28fajnAQCA0BBGmozLzZbDlq5gC3gtkhy2dI3LzY5lswAASHiEkSapKRYtnp4nSa0Ciff54ul51BsBACDCCCPNFOU7tHJWgew2/6EYuy1dK2cVqCjfYVLLAABIXGHtTZMMivIdmpJn14rNH2v5po81PCdDGx66iR4RAACihJ6RAFJTLJo0sr8kqerCJYIIAABRRBgJYmCfHpKkv9fUq+5io8mtAQAgcRFGgujdM00Z3VMlSZ9WXTC5NQAAJC7CSBAWi0UD+/SUJH3yGWEEAIBoIYy0YVD25aGaTz47b3JLAABIXISRNtAzAgBA9BFG2uCdxEoYAQAgeggjbRjQVPzsgxNVKj1yVo0ew+QWAQCQeAgjQWwod+rnfz4gSTpWeV4znt2hLz+xWRvKnSa3DACAxEIYCWBDuVNzS8p05lyD33GXu05zS8oIJAAARBBhpIVGj6Gl6w8q0ICM99jS9QcZsgEAIEIIIy3srKiU010X9HVDktNdp50VlbFrFAAACYww0sLpmuBBpCPnAQCAthFGWsjJTI/oeQAAoG2EkRbG5WbLYUtXsH16LZIctnSNy82OZbMAAEhYhJEWUlMsWjw9T5JaBRLv88XT85SaEiyuAACAcBBGAijKd2jlrALZbf5DMf16WbVyVoGK8h0mtQwAgMTTzewGdFVF+Q5NybNrZ0WlfrpmvyrO1GrR1JEEEQAAIoyekTakplhUeHVffWV4P0nSoVM1JrcIAIDEQxgJwTWOLEnSQWe1yS0BACDxEEZC4A0j/3uiSuv2fcqmeQAARBBzRkJw7GytJKm67pIWvLxP0uXlvYun5zGHBACATqJnpB0byp16qCmANMemeQAARAZhpA1smgcAQPQRRtrApnkAAEQfYaQNoW6Gt/GgK8otAQAgcRFG2hDqZnjPv3eUuSMAAHQQYaQN3k3z2mMRc0cAAOgowkgbmm+a1xbmjgAA0HGEkXYU5Tt0/8ShIZ0b6hwTAADwOcJICCbn2UM6L9Q5JgAA4HNhhZGVK1dq9OjRysrKUlZWlgoLC/Xmm28GPX/VqlWyWCx+j/T0+Lthe+eOWIK8btHliqzjcrNj2SwAABJCWGFk4MCBevzxx7Vnzx7t3r1bkyZN0p133qkDBw4EfU9WVpacTqfvcezYsU43Otaazx0JFEgMSY9Mu0apKcHiCgAACCasMDJ9+nTdfvvtGj58uL7whS/o3/7t39SrVy/t2LEj6HssFovsdrvv0b9//0432gxF+Q6tnFUge5DVNY/95W8s7wUAoAM6PGeksbFRL7/8smpra1VYWBj0vHPnzmnIkCEaNGhQu70oXvX19aqurvZ7dAVF+Q49Mi3w6hr2qgEAoGPCDiP79+9Xr169ZLVa9eCDD2rNmjXKywt8gx4xYoSef/55rVu3TiUlJfJ4PLrhhhv0ySeftPkdxcXFstlsvsegQYPCbWZUNHoMPfaXgwFfM5oeS/58gHojAACEwWIYRlh3zoaGBh0/flxut1uvvvqqnnvuOb377rtBA0lzFy9e1DXXXKMZM2boscceC3pefX296uvrfc+rq6s1aNAgud1uZWVlhdPciCo9clYzng0+JOU1Nd+u2YVDNS43m3kkAICkVV1dLZvN1u79u1u4H9y9e3cNGzZMkjR27Fjt2rVLTz75pJ5++ul235uWlqbrr79ehw8fbvM8q9Uqq9UabtOiLtQ6Im+Wu/RmuUsOW7oWT89TUb4jyi0DACB+dbrOiMfj8evFaEtjY6P2798vhyM+b87h1hFhHgkAAO0Lq2dk0aJFmjp1qgYPHqyamhqtXr1aW7Zs0VtvvSVJmj17tq688koVFxdLkh599FFNmDBBw4YNU1VVlZYtW6Zjx47pgQceiPyVxIC33ojTHVoPiaHP962ZkmdnyAYAgADCCiOnT5/W7Nmz5XQ6ZbPZNHr0aL311luaMmWKJOn48eNKSfm8s+Wzzz7TnDlz5HK51KdPH40dO1bbt28PaX5JV+StN/JgSVnI72m+b03h1X2j1zgAAOJU2BNYzRDqBJhYeXLTR1q+6ePw3vOt63TndVdGqUUAAHQ9od6/2ZumA+ZPGi57VnjzR9i3BgCAwAgjHZCaYtGSO/KC7lXTHPvWAADQNsJIB3nLwzuClIeXPt/HZvH0PCavAgAQRNh1RvC5onyHpuTZtbOiUhsPurR230lV1jb4XrdTZwQAgHbRM9JJqSkWFV7dVz+ffq12/b/J+tU/jbl83CL9aMoXZOvRnfLwAAC0gZ6RCEpNsahnWqosFqnRkH786geSRCVWAADaQM9IBG0od+r7L5ap5WJpKrECABAcYSRCGj2Glq4/qEADMt5jS9cfZMgGAIAWCCMRsrOiss0y8c0rsQIAgM8RRiIk1B19Qz0PAIBkQRiJkFArrFKJFQAAf4SRCPHu6BustBmVWAEACIwwEiHeHX0ltQokVGIFACA4wkgEeUvE21uUiLfb0rVyVgF1RgAACICiZxHmLRH/5n6n5r+0VykWafOPblaP7qlmNw0AgC6JnpEoSE2xaNpohzLTu8ljSEfP1prdJAAAuizCSJRYLBaN7J8pSVr9/jGVHjlLwTMAAAJgmCZKNpQ7dcBZLUn6447j+uOO4+xRAwBAAPSMRMGGcqfmlpTpfEOj33Gnu04PlpTpjQ9OmtQyAAC6HsJIhLW1R43X/Jf26o0P2DQPAACJMBJx7e1RI0keQ/r+anbxBQBAIoxEXDh7z7CLLwAAhJGIC2fvGae7TjuOnI1iawAA6PoIIxHm3aMmVPMYrgEAJDnCSIQ136MmFFUXLmpuCYEEAJC8CCNRUJTv0H9++3qFuieeIWnJnw8wfwQAkJQII1Fy++gBWjGjIOTzXdX1WvjqBwQSAEDSIYxE0e2jHXpqVoF690gL6fxXyz7R2H/dyJANACCpEEairCjfod/ODL2HpOo8c0gAAMmFMBIDE67qG9YKG0PUIAEAJA/CSAyEu8JGulyDZGdFZZRaBABA10EYiZGifId+OHl4WO8Jp5orAADxijASQ/MnDZc9K/Thmn4Z1ii2BgCAroEwEkOpKRYtuSP04Zrvry7Tk5s+Yu4IACChEUZirCi/ablvz/aX+7ovXNTyTR+z3BcAkNAIIyYoyndoz8+m6IeTvyBberd2z2e5LwAgkRFGTJKaYtGCycP1n7PGhnQ+JeMBAImKMGKyM+fqQz7XVV2vFZsPR7E1AADEHmHEZDmZoa+ukaTlmz5iuAYAkFAIIyYbl5sdVnVWieqsAIDEElYYWblypUaPHq2srCxlZWWpsLBQb775ZpvveeWVVzRy5Eilp6dr1KhReuONNzrV4ETT0eqsO46cVemRs1q371OVHjlLOAEAxC2LYRgh38XWr1+v1NRUDR8+XIZh6Pe//72WLVumvXv36tprr211/vbt23XjjTequLhYX/va17R69Wo98cQTKisrU35+fsiNrK6uls1mk9vtVlZWVsjviycbyp36l9f2q+r8xZDO794tRQ2XPL7nDlu6Fk/PU1G+I1pNBAAgLKHev8MKI4FkZ2dr2bJluv/++1u9dvfdd6u2tlavv/6679iECRN03XXX6amnngr5O5IhjEhSo8fQwlc/0Ktln4T9XkvT/66cVUAgAQB0CaHevzs8Z6SxsVEvv/yyamtrVVhYGPCc0tJSTZ482e/YbbfdptLS0o5+bUJLTbHoiX8YHVbJeC9vomQ+CQAg3oQdRvbv369evXrJarXqwQcf1Jo1a5SXF3jOg8vlUv/+/f2O9e/fXy6Xq83vqK+vV3V1td8jWYRbMr45Q+z2CwCIP2GHkREjRmjfvn16//33NXfuXN1zzz06ePBgRBtVXFwsm83mewwaNCiin9/VFeU7dP/EoR1+P7v9AgDiSdhhpHv37ho2bJjGjh2r4uJijRkzRk8++WTAc+12u06dOuV37NSpU7Lb7W1+x6JFi+R2u32PEydOhNvMuDc5r+3/j9oSbu0SAADM1Ok6Ix6PR/X1gauIFhYW6u233/Y7tnHjxqBzTLysVqtv+bD3kWy89Ucs7Z/qx55l1bjc7Ki0CQCAaAgrjCxatEhbt27V0aNHtX//fi1atEhbtmzRzJkzJUmzZ8/WokWLfOcvWLBAGzZs0K9+9St9+OGHWrJkiXbv3q358+dH9ioSUEfqj0hSdd0lrdj8MZNYAQBxI6wwcvr0ac2ePVsjRozQLbfcol27dumtt97SlClTJEnHjx+X0/l5qfIbbrhBq1ev1jPPPKMxY8bo1Vdf1dq1a8OqMZLMivIdWjmrIKwKrecbGrV808ca+68bKRsPAIgLna4zEgvJUmckmEaPoZ0Vldp40KW1+06qsrYhpPdZdLnuyJQ8u3ZWVOp0TZ1yMtM1LjdbqSnhDgABABCemBU9i4VkDyPNNXoMrXqvQo/95W8hnd/Lmqpe1jS5qj9fYUO1VgBALES96BnMkZpiUb9Ma8jnn6tv9AsikuRy12luSRnDOACALoEwEoc6u3TXaHos+fMBJroCAExHGIlD3mW/neWqrteKzYcj0CIAADqOMBKHOrrsN5Dlmz5iuAYAYCrCSJwqynfoqVkF6t0zrdOf9dM1+7Vm76cqPXKWYRsAQMyxmibONXoMrdh8WM9sPaLahsZOfx4rbQAAkcJqmiSRmmLRgsnDtffntyo7o3unP4+VNgCAWCOMJIju3VL0i693vrKtt5ts6fqDDNkAAGKCMJJAivId+uHk4Z3+HEOS012nnRWVnW8UAADtIIwkmPmThsue1fllv5L0ZrmTSa0AgKgjjCSY1BSLltyRJ4su703TGX8oPaYZz+7Ql5/YzBwSAEDUEEYSkHe3X3uLwmj9M7url7Vb2J/HpFYAQDSxtDeBeXf79e7W6zEMzXzu/Q59lkWS3ZaubQsnseMvACAkod6/w//PZMSN1BSLCq/u63u+bt+nHf6s5pNam38mAACdRRhJIp3dYE+S/mvXcbmq62TPSte43Gx6SQAAnUYYSSLeDfZc7jp1dGxu7b6TWrvvpCSqtQIAIoMJrEmk+QZ7kejPcDKxFQAQAYSRJBNspU1nUK0VANAZhJEkVJTv0LaFk/TItGs6/Vneia2//ushCqQBADqEpb1JrNFj6MtPbO7UHJKW7FlWzRg3WEP7ZSgnk0muAJDMQr1/E0aS3IZyp+aWlElSxAJJc0xyBYDkFer9m2GaJBeNOSTNUb0VANAeekYgyb9a69Ez5/WbTR9FrKeE6q0AkJyowIqwtKzWOsLeS0vXH5TTXdfpz6Z6KwCgLYQRBFSU79CUPLt2VlTK5b6gytoGnTnXoJXvHunwZ7rcFyLYQgBAoiCMIKiWvSWNHkNr933a4d6Sx/7yN/XonspkVgCAHyawImTeCq4dnfVRWdugB0vK9Nj6A76aJI0eQ6VHzmrdvk+pUwIASYoJrAjbhnJnROaT9O6ZJkmqOn/Rd4ylwACQOKgzgqjyrr756wGnXth+LOKff//EoZqcZ6doGgDEMcIIYiZSPSWB0FMCAPGLMIKY8vaUvHf471rxTsdX3LTk7RNZOauAQAIAcYYKrIgp78qbH04ZIUcEq7l6k/LS9QfVcMnDZFcASED0jCDiNpQ79WDTfjeRlJ3RXZW1Db7nDOEAQNdGzwhMU5Tv0A8nD4/45zYPIpL/vjcsEQaA+EXPCKKi0WNo4uOb5aqO/KTW5iySbD3TlN4t1e+76DUBAPPRMwJTpaZYtOSOywXSorkw19DlOiUtQw+7BQNA/CCMIGqK8h1aOatA9ghOaA2V0fRY8ucDDNkAQBdHGEFUFeU7tG3hJL00Z4K+M3GopOj2lLTkqq7Xis2HY/iNAIBwEUYQdd5lvz+ffq2eMqGnZPmmjxiuAYAujAmsiDlvgbTTNXU6eua8frPpI0mf1xSJBoctXdsWTgq5tHzzNuZkplOWHgA6INT7d7dwPrS4uFivvfaaPvzwQ/Xo0UM33HCDnnjiCY0YMSLoe1atWqX77rvP75jValVdXXRXWaDr8vaUeI2w94paOXkvp7tOyzd+pInD+rUbLAKVt2d1DgBET1jDNO+++67mzZunHTt2aOPGjbp48aJuvfVW1dbWtvm+rKwsOZ1O3+PYschvrIb45Z1X8uL949W7R1rUvmfFO4c149kd+vITm4MO22wod2puSVmrYMTqHACInrB6RjZs2OD3fNWqVcrJydGePXt04403Bn2fxWKR3W7vWAuRFFJTLEpJsajqwsWof5fTXacHS8p03w1DdOu1Dl9PSaPH0NL1BwMOFxm6PPF26fqDmpJnZ8gGACIorDDSktvtliRlZ2e3ed65c+c0ZMgQeTweFRQU6Be/+IWuvfbaoOfX19ervr7e97y6urozzUScOF0T26G7F7Yf0wvbj/mGYGw9urc5VGTocpDZWVHpN8wEAOicDq+m8Xg8euihhzRx4kTl5+cHPW/EiBF6/vnntW7dOpWUlMjj8eiGG27QJ598EvQ9xcXFstlsvsegQYM62kzEkZzM0FbZRLpTwttT8ofSoyGdH+vQBACJrsOraebOnas333xT27Zt08CBA0N+38WLF3XNNddoxowZeuyxxwKeE6hnZNCgQaymSXCNHkNffmKzXO66oCtrsjPS9N7CW7TvRJVO19SpX4ZVskhnztXr6JnzeuG9iqgP9bw0ZwI9IwAQgqispvGaP3++Xn/9dW3dujWsICJJaWlpuv7663X4cPBCVFarVVartSNNQxxLTbFo8fQ8zS0pk0X+S329nSG/+Poo9eieGjAMNHoMvbTzuBSlMGKRZLddXuYLAIicsIZpDMPQ/PnztWbNGm3evFm5ublhf2FjY6P2798vh4MlkmgtWAl5uy1dK2cVtLm0dmdFZVQ35jMkPTLtmoCTV9k1GAA6LqyekXnz5mn16tVat26dMjMz5XK5JEk2m009evSQJM2ePVtXXnmliouLJUmPPvqoJkyYoGHDhqmqqkrLli3TsWPH9MADD0T4UpAoivIdmpJnD7voWCzmcjz2l79JkvpkWOVyX1BlbYM+qbqgdftOqrK2wXdeoLokFFIDgMDCCiMrV66UJN18881+x1944QXde++9kqTjx48rJeXzDpfPPvtMc+bMkcvlUp8+fTR27Fht375deXl5nWs5ElrLwmihCHUCbGc43XX6/uq97Z7nrUvi7c2hkBoABEc5eCSMUCbAxpJ3jskj0/I0b3VZqzZ5+0TaG34CgHgV6v2bjfKQMLwTYKXY7gwcjLcuyc/WlQctpGZI+pc/7dd7h88wzwRA0iKMIKEEmwDrsKXrP799vR6Zdk3M29R8LkkgVRcuauZz77dZph4AEhnDNEhIwSaLdrWhnOYYtgGQaBimQVLzToC987orVXh1X9+qla42lNOcNxwtXX+QIRsASYUwgqQTbCinK/DOM1m+8SPqlQBIGgzTIGl5h3LeLHfqD6XHzG5OQPYsq2aMG6yh/TKC1iZpPiTVvDw+tUwAmC2q5eCBRNC8lklXDSOu6not3/Sx73nL2iSB6pc0Ry0TAPGAnhEkvVAntbbcL8frnsLBWv+Bq91VM5H00C3DVF13Sc+/d7TN85gUC8BMTGAFQtTWpFZL0+N7N+YGXC781KwCFeUPiGkQkaTfvH243SAiMSkWQHxgmAbQ55NaWw552JsNc/zfomsCLhdet+9TE1vePu+k2J0VlWGX2AeAWCCMAE3a26Av2H45sdgTJxI2HnQRRgB0SYQRoJmObNA3LjdbDlt6lyyk1tzz7x3VF4f00W35Du2sqPTtOpzdyyp7FitvAJiHCaxABGwod2puSZmkwJNc7584VJPz7PqstkGP/SX46pdos0iy9UxT1fmLrV5j5Q2ASAv1/k0YASIk0DLbQDf4Ro+h5Rs/0op3DpvRzHb957ev9/WeBBquAoBQEUYAEwTbE6el0iNnNePZHSa0sH2Bek/oNQHQERQ9A0wQ6pyTrjzPxJBaDeO43HWaW1Km3377evXJsNJjAiCi6BkBTBJsnom3uNoPJw/X0H4ZOnrmvF7aeVyuanPmmTTXsvAbPSYA2sIwDRAHwplnsrOiUu8d/rtWvHPEjKYG1DI4hbJ/Dj0qQPIgjABxIpwbdXul6y2Ssnp0U03dJZlVcDWU/XPoUQGSA2EESFBtDe9Il/eh8Xik768ui3nbWrZDkuaWlLUKTs3PaavQHID4RhgBElgovQ1PbvrIb8ffWLJI6p9llWRpc65L7x7dlJ7Wze+c3j3SdN/EoZo/aTihBIhzhBEgwbU3vNPoMTTx8c1dYuJrR/TumabHvzGKoRwgjrFrL5DgvMuI77zuShVe3bdVL0JqikVL7sjz7TzcnPfYnK8MVVftfKg6f1EPlpTpjQ9Omt0UAFFGGAESmHc3YrvNfzM/uy1dK2cV6P9Nu1YrZhSY1LrQzH9pr974wGl2MwBEEcM0QBJob0gn0ByUruaHk4cHnEfCsmGg62LOCICweG/qLvcFPfaXv+mz2oYuVx22f6ZV3x4/2FfTJNDGgywbBroOwgiADmtvF+J44N0pmZ4SwDyEEQCdEmz58B1jHHpma4Wk+Agq2Rlp+vp1VxJMABMQRgB0WrD5GPEwxyQQe5ZVM8YNbrN0PYDIIYwAiKpGj6HlGz/SincOm92UDmN+CRBd1BkBEFWpKRZNHNavw+/PTO/m97x3j25Bzowel7tOc0vKtKHcqUaPodIjZ7Vu36cqPXJWjWZt7gMkodj/6QeQMMblZsthSw+6cV9bHr3jWtltPfyGgDYedGnJnw/IVV0flfa25G3zj1/5X6Wm7Jf7wkXfa/SaALHDMA2ATunoypuX5kxQ4dV9Wx1v9Bhasfmwlm/6KEIt7JxAq3KobQKEhjkjAGImnAmtFl2uALtt4aQ2b+Abyp36l9f2q+r8xaDnxJK3p0RSu5sUAriMMAIgppr3Fhw9c16/aerZaP4XjDd6rJxV0O6NO542+gvnuoBkEur9mzkjACLCu3Gf1wh7r1Y9CPYwehB2VlTGRRCRPg9cS/58QFPy7AzZAGEijACIiqJ8h6bk2Ts8t+J0TWhBpJc1VbX1jV2iAJurul7//vbHmnBV34DXzFwTIDDCCICoadlbEo6czPT2T5I05ytX6zebPpJFXaMi7JNvf6wn3/7Y95y5JkD7mDMCoEtq9Bj68hObgy4bbj4RduNBV6sbfe8eaaq60DUmvwbTfK5JZ3qRgK6KCawA4l6wZcOBJoy2HALxGIZmPvd+bBvcARZJtp5pSu+W6jdHhl4TJALCCICEEGzDvvZu1O31rMSL//z29bp99ACzmwF0SFTKwRcXF+tLX/qSMjMzlZOTo7vuukuHDh1q932vvPKKRo4cqfT0dI0aNUpvvPFGOF8LIIkV5Tu0beEkvTRngp781nV6ac4EbVs4qd0eg9QUi2+uRnuDHX16dlNG99QItTiy5r+0V2984Ozw+ylzj3gQVs9IUVGRvvWtb+lLX/qSLl26pJ/+9KcqLy/XwYMHlZGREfA927dv14033qji4mJ97Wtf0+rVq/XEE0+orKxM+fn5IX0vPSMAOipQz0qg3Xs3HnR1qJJsrDwVYg2TlvVeXtp5nOEfmCYmwzR///vflZOTo3fffVc33nhjwHPuvvtu1dbW6vXXX/cdmzBhgq677jo99dRTIX0PYQRAZ4S6pDZQcOndM00Nlzw639AYyya34rCl692ffFV7jn0ml/uCKmsblN3LKnvW59cTSiVcCrQhlmJS9MztdkuSsrOzg55TWlqqhx9+2O/YbbfdprVr1wZ9T319verrP98oq7q6ujPNBJDkQl1iHKw2iiSt2HxYL7xX4bdCJ5bLiZ3uOk0ofluVtQ2tXnPY0nXHGIee2VrRbnsMXW730vUHKdCGLqPDYcTj8eihhx7SxIkT2xxucblc6t+/v9+x/v37y+VyBX1PcXGxli5d2tGmAUCHBQsuCyYP1/xJw/yCyqVGj/75+Z0xa1ugICJdDipPb60I+XOMpvfsrKjscB0YIJLCmsDa3Lx581ReXq6XX345ku2RJC1atEhut9v3OHHiRMS/AwDC5Q0qd153pQqv7qvK84HDQbzYeDD4fxQCsdShnpH58+fr9ddf19atWzVw4MA2z7Xb7Tp16pTfsVOnTslutwd9j9VqldVq7UjTACBmQq0S21U9/95RjcvNbneJNMXYEG1hhRHDMPSDH/xAa9as0ZYtW5Sbm9vuewoLC/X222/roYce8h3buHGjCgsLw24sAHQl43Kz5bClx20tk/bmjnS0xgsQrrCGaebNm6eSkhKtXr1amZmZcrlccrlcunDhgu+c2bNna9GiRb7nCxYs0IYNG/SrX/1KH374oZYsWaLdu3dr/vz5kbsKADBBOLVMuqLmc0da8la/bbkyx+Wu09ySMm0o/7z2ibeWyZqyT/S7//n/tGYvNU0QnrCW9losgf+4vfDCC7r33nslSTfffLOGDh2qVatW+V5/5ZVX9LOf/UxHjx7V8OHD9ctf/lK33357yI1kaS+ArizgkuAO7I1j1n46/zxhsG4fNcC3cmjHkbOat7osaFu8+wK9+5OvauWWI61WGXnRiwLKwQNADHV0b5x/njBYBUOyZc8yfz+dnt1TlWKx6Fz9pZDOT++WorpLnjbPsYiaJsksJnVGAACXtVwS3Ogx2pxP4u1dWHJHvm++hvc9bRUti6ZwC7u1F0Sky0NBP12zX5NG9lf3bh1ewIkEx78ZABAFbc0n8T5fPD3Pb+Jo8/ckksrai5pQ/LbfPJNA2EcneTFMAwBR1JEVKRvKnfqX1/ar6nzreRje6PLAV4bqd9uOKp7u120N2bByJzExZwQAuoiO1Opo9BgBS9A3v0G/8YFT319dFu3mR4x3aGrbwkl+1x/sOthHJ/4RRgAgAbQXZELZHK+reWTaNbp3Yq5SUyx644OTmv/S3qA9PMECDOIDYQQAkkTzwHL0zHn9ZtNHkmK3iV9HeDf3C3VPnZfmTAi6jw5VYrsuVtMAQJJouZJnhL1XwPkXoe7sGwvhbu53uiZwz0+gniF7llUzxg3W0H4ZhJM4QRgBgARTlO/QlDx7wN6C6wf3idqwTo9uFsli0YWL7S/5DVegfYC8VWJbhitXdb2Wb/rY95yJsF0fwzQAkGS8wxou9wW9d/iMNv7ttNydqPzau0ea7ps4VPMnDdfGgy49WBLZSbWOpmqve4595gtXY4f00U3L3gkpVDER1jzMGQEAhKQjc06yM9L09euu1OQ8e6thkMfWH9Dv3jsasfZ978Zc/fl/nX7BI6N7qmrDKNLGRFhzMGcEABCSUOachDMPY3KePSJhxGKRHvhybsB5LuEEEcl/U8BgE2FhHsIIAMBPW3NOQjEuNzsiZe2/OLi3/nv3JxGdcOtyX1DpkbNyuS+osrZB2b2syulllSzSmXP1THg1CcM0AICICza5NBQ9u6eGvU9OqLIzuquytqHNczo64ZUlxq0xZwQAYKp4LMjW3P0ThwacExNIuOXskyW4EEYAAKZr9BjaceSsvr+6rFMrdszU1mRdKXgvULBVPMm0Dw9hBADQZXRm2KYraRkaGj2GvvzE5qC9Py1X8STbPjyh3r9TYtgmAECSKsp3aOWsAvXukWZ2UzrF5a7T3JIybSh3SpJ2VlS2OQzlXcWz48hZLd/4keYF2djQG9KWrj+oxnjaijlCWE0DAIiJonyHMtPTNPO5981uSod5Y8LCP32gzPQ0na6pD+l9c/64u91Jucm8/JgwAgCImQlX9ZXDli6Xuy6uh2zcFy5p5nPvK8OaGtL54awOCrYPTyJjmAYAEDOpKRYtnp4n6fN5El7hrCW5f+JQvXj/eL34wHh9Z+LQsN8fKbX1kV+CHGgfnkRHzwgAIKa880daVXltmhwqKeiS4ECrTiYO66dxudlxvYzYy55l1bjc7KCvJ+qSYFbTAABM0daNtflmft5Kqfastm++LffYWd60x05bstJT1S0lVZXn2y6EFisZ1lR964uDAi4jjsclwSztBQAktQ3lTv3La/tVdb51fZPmS2klaW7TTsNd6YbYPGiEUsukMyX8o4UwAgBIeo0eQys2H9YL71WoqlnRtZY9CoF6HazdUlR/yRPzNrd0T+Fgrf/AFbSMvUWSrWea0rulylXdenPDwdk9Q+5dijTCCAAATUKZa9HynLFD+ujGX77jd4NPBLEc2iGMAADQSYlSObYli2JT7ZUKrAAAdJJ35Y/DlnjLbbtStVfCCAAAbSjKd2jbwkma/9Vhnf4siy7P5bBnpZtSF8WreZn6roAwAgBAO1JTLJo4rF+nP8eQtOSOa7XkjrzONyoC5vxht57c9JHpPSSEEQAAQjAuN1sOW+d6NL4zcaiK8h1dZvjn/MVGLd/0scb+60bf5n9mIIwAABCCtkrZh2pKnt33z97hn5fmTNC9NwyRxcRxm6rzF/12I441wggAACHy9mjYW/Ro2LOs6t0zLWhIsejyktqWpd5TUywqvLqvltyRr9/OKIhOo0NkSFry5wOmDNmwNw0AAGEoyncErHa68aBLc0vKZJF/JVdvQFk8Pa/NYmO3j3boqZTWe/bEkqu6Xis2H9aCycNj+r3UGQEAIEIisX9M83153jt8Rq+WfRqt5gb1VIRqkFD0DAAAE0R6Z91AASfaHLZ0bVs4qdNl40O9fzNMAwBABHnngURKy2Gho2fO66Wdx/3K1NvSu6nRkGrrL0WkWqzTXaedFZURvY62EEYAAOjiWgac+ZOGhT1n5bs35uq/dn8ScBfjQE7XxK4nhtU0AADEGW84ufO6K1V4dV+lpliCr/SxpWvlrAItuj1Pe342Rf9QMDCk78jJjF0NFHpGAABIEMFW+njnfqSmWPTEP4zWtsNngu5GbNHlANNyGXI0EUYAAEgg7c1ZSU2xaMkdeZpbUiapY8uQIy3sYZqtW7dq+vTpGjBggCwWi9auXdvm+Vu2bJHFYmn1cLlcHW0zAADohPaGdCKxrDccYfeM1NbWasyYMfrOd76jb3zjGyG/79ChQ37LenJycsL9agAAECHtDenEUthhZOrUqZo6dWrYX5STk6PevXuH/T4AABAdkV6G3FExW01z3XXXyeFwaMqUKXrvvffaPLe+vl7V1dV+DwAAkJiiHkYcDoeeeuop/elPf9Kf/vQnDRo0SDfffLPKysqCvqe4uFg2m833GDRoULSbCQAATNKpcvAWi0Vr1qzRXXfdFdb7brrpJg0ePFh//OMfA75eX1+v+vp63/Pq6moNGjSIcvAAAMSRLl0Ofty4cdq2bVvQ161Wq6xWawxbBAAAzGJKBdZ9+/bJ4YjtsiEAANA1hd0zcu7cOR0+fNj3vKKiQvv27VN2drYGDx6sRYsW6dNPP9Uf/vAHSdJvfvMb5ebm6tprr1VdXZ2ee+45bd68WX/9618jdxUAACBuhR1Gdu/era9+9au+5w8//LAk6Z577tGqVavkdDp1/Phx3+sNDQ360Y9+pE8//VQ9e/bU6NGjtWnTJr/PAAAAyatTE1hjJdQJMAAAoOsI9f7Nrr0AAMBUcbFRnrfzhuJnAADED+99u71BmLgIIzU1NZJE8TMAAOJQTU2NbDZb0NfjYs6Ix+PRyZMnlZmZKYslchv4eIupnThxImHnonCN8S/Rr0/iGhNBol+flPjXGI3rMwxDNTU1GjBggFJSgs8MiYuekZSUFA0cODBqn5+VlZWQ/2I1xzXGv0S/PolrTASJfn1S4l9jpK+vrR4RLyawAgAAUxFGAACAqZI6jFitVi1evDih98HhGuNfol+fxDUmgkS/Pinxr9HM64uLCawAACBxJXXPCAAAMB9hBAAAmIowAgAATEUYAQAApkrqMPLb3/5WQ4cOVXp6usaPH6+dO3ea3aQOKS4u1pe+9CVlZmYqJydHd911lw4dOuR3zs033yyLxeL3ePDBB01qcfiWLFnSqv0jR470vV5XV6d58+apb9++6tWrl775zW/q1KlTJrY4fEOHDm11jRaLRfPmzZMUf7/h1q1bNX36dA0YMEAWi0Vr1671e90wDP385z+Xw+FQjx49NHnyZH388cd+51RWVmrmzJnKyspS7969df/99+vcuXMxvIq2tXWNFy9e1MKFCzVq1ChlZGRowIABmj17tk6ePOn3GYF+98cffzzGVxJce7/jvffe26r9RUVFfud05d+xvesL9GfSYrFo2bJlvnO68m8Yyv0hlL8/jx8/rmnTpqlnz57KycnRT37yE126dCli7UzaMPJf//Vfevjhh7V48WKVlZVpzJgxuu2223T69Gmzmxa2d999V/PmzdOOHTu0ceNGXbx4Ubfeeqtqa2v9zpszZ46cTqfv8ctf/tKkFnfMtdde69f+bdu2+V774Q9/qPXr1+uVV17Ru+++q5MnT+ob3/iGia0N365du/yub+PGjZKkf/zHf/SdE0+/YW1trcaMGaPf/va3AV//5S9/qX//93/XU089pffff18ZGRm67bbbVFdX5ztn5syZOnDggDZu3KjXX39dW7du1Xe/+91YXUK72rrG8+fPq6ysTI888ojKysr02muv6dChQ7rjjjtanfvoo4/6/a4/+MEPYtH8kLT3O0pSUVGRX/tfeuklv9e78u/Y3vU1vy6n06nnn39eFotF3/zmN/3O66q/YSj3h/b+/mxsbNS0adPU0NCg7du36/e//71WrVqln//855FrqJGkxo0bZ8ybN8/3vLGx0RgwYIBRXFxsYqsi4/Tp04Yk49133/Udu+mmm4wFCxaY16hOWrx4sTFmzJiAr1VVVRlpaWnGK6+84jv2t7/9zZBklJaWxqiFkbdgwQLj6quvNjwej2EY8f0bSjLWrFnje+7xeAy73W4sW7bMd6yqqsqwWq3GSy+9ZBiGYRw8eNCQZOzatct3zptvvmlYLBbj008/jVnbQ9XyGgPZuXOnIck4duyY79iQIUOM5cuXR7dxERLoGu+55x7jzjvvDPqeePodQ/kN77zzTmPSpEl+x+LpN2x5fwjl78833njDSElJMVwul++clStXGllZWUZ9fX1E2pWUPSMNDQ3as2ePJk+e7DuWkpKiyZMnq7S01MSWRYbb7ZYkZWdn+x1/8cUX1a9fP+Xn52vRokU6f/68Gc3rsI8//lgDBgzQVVddpZkzZ+r48eOSpD179ujixYt+v+fIkSM1ePDguP09GxoaVFJSou985zt+m0PG+2/oVVFRIZfL5feb2Ww2jR8/3veblZaWqnfv3vriF7/oO2fy5MlKSUnR+++/H/M2R4Lb7ZbFYlHv3r39jj/++OPq27evrr/+ei1btiyi3d+xsGXLFuXk5GjEiBGaO3euzp4963stkX7HU6dO6S9/+Yvuv//+Vq/Fy2/Y8v4Qyt+fpaWlGjVqlPr37+8757bbblN1dbUOHDgQkXbFxUZ5kXbmzBk1Njb6/R8rSf3799eHH35oUqsiw+Px6KGHHtLEiROVn5/vO/7tb39bQ4YM0YABA/TBBx9o4cKFOnTokF577TUTWxu68ePHa9WqVRoxYoScTqeWLl2qr3zlKyovL5fL5VL37t1b/QXfv39/uVwucxrcSWvXrlVVVZXuvfde37F4/w2b8/4ugf4Mel9zuVzKycnxe71bt27Kzs6Oy9+1rq5OCxcu1IwZM/w2Ifs//+f/qKCgQNnZ2dq+fbsWLVokp9OpX//61ya2NnRFRUX6xje+odzcXB05ckQ//elPNXXqVJWWlio1NTWhfsff//73yszMbDUEHC+/YaD7Qyh/f7pcroB/Vr2vRUJShpFENm/ePJWXl/vNp5DkNz47atQoORwO3XLLLTpy5IiuvvrqWDczbFOnTvX98+jRozV+/HgNGTJE//3f/60ePXqY2LLo+N3vfqepU6dqwIABvmPx/hsms4sXL+qf/umfZBiGVq5c6ffaww8/7Pvn0aNHq3v37vre976n4uLiuCg7/q1vfcv3z6NGjdLo0aN19dVXa8uWLbrllltMbFnkPf/885o5c6bS09P9jsfLbxjs/tAVJOUwTb9+/ZSamtpqtvCpU6dkt9tNalXnzZ8/X6+//rreeecdDRw4sM1zx48fL0k6fPhwLJoWcb1799YXvvAFHT58WHa7XQ0NDaqqqvI7J15/z2PHjmnTpk164IEH2jwvnn9D7+/S1p9Bu93eakL5pUuXVFlZGVe/qzeIHDt2TBs3bmx3a/bx48fr0qVLOnr0aGwaGGFXXXWV+vXr5/v3MlF+x//5n//RoUOH2v1zKXXN3zDY/SGUvz/tdnvAP6ve1yIhKcNI9+7dNXbsWL399tu+Yx6PR2+//bYKCwtNbFnHGIah+fPna82aNdq8ebNyc3Pbfc++ffskSQ6HI8qti45z587pyJEjcjgcGjt2rNLS0vx+z0OHDun48eNx+Xu+8MILysnJ0bRp09o8L55/w9zcXNntdr/frLq6Wu+//77vNyssLFRVVZX27NnjO2fz5s3yeDy+INbVeYPIxx9/rE2bNqlv377tvmffvn1KSUlpNbQRLz755BOdPXvW9+9lIvyO0uXeyrFjx2rMmDHtntuVfsP27g+h/P1ZWFio/fv3+4VKb7DOy8uLWEOT0ssvv2xYrVZj1apVxsGDB43vfve7Ru/evf1mC8eLuXPnGjabzdiyZYvhdDp9j/PnzxuGYRiHDx82Hn30UWP37t1GRUWFsW7dOuOqq64ybrzxRpNbHrof/ehHxpYtW4yKigrjvffeMyZPnmz069fPOH36tGEYhvHggw8agwcPNjZv3mzs3r3bKCwsNAoLC01udfgaGxuNwYMHGwsXLvQ7Ho+/YU1NjbF3715j7969hiTj17/+tbF3717fSpLHH3/c6N27t7Fu3Trjgw8+MO68804jNzfXuHDhgu8zioqKjOuvv954//33jW3bthnDhw83ZsyYYdYltdLWNTY0NBh33HGHMXDgQGPfvn1+fza9KxC2b99uLF++3Ni3b59x5MgRo6SkxLjiiiuM2bNnm3xln2vrGmtqaowf//jHRmlpqVFRUWFs2rTJKCgoMIYPH27U1dX5PqMr/47t/XtqGIbhdruNnj17GitXrmz1/q7+G7Z3fzCM9v/+vHTpkpGfn2/ceuutxr59+4wNGzYYV1xxhbFo0aKItTNpw4hhGMZ//Md/GIMHDza6d+9ujBs3ztixY4fZTeoQSQEfL7zwgmEYhnH8+HHjxhtvNLKzsw2r1WoMGzbM+MlPfmK43W5zGx6Gu+++23A4HEb37t2NK6+80rj77ruNw4cP+16/cOGC8f3vf9/o06eP0bNnT+PrX/+64XQ6TWxxx7z11luGJOPQoUN+x+PxN3znnXcC/nt5zz33GIZxeXnvI488YvTv39+wWq3GLbfc0uq6z549a8yYMcPo1auXkZWVZdx3331GTU2NCVcTWFvXWFFREfTP5jvvvGMYhmHs2bPHGD9+vGGz2Yz09HTjmmuuMX7xi1/43cjN1tY1nj9/3rj11luNK664wkhLSzOGDBlizJkzp9V/1HXl37G9f08NwzCefvppo0ePHkZVVVWr93f137C9+4NhhPb359GjR42pU6caPXr0MPr162f86Ec/Mi5evBixdlqaGgsAAGCKpJwzAgAAug7CCAAAMBVhBAAAmIowAgAATEUYAQAApiKMAAAAUxFGAACAqQgjAADAVIQRAABgKsIIAAAwFWEEAACYijACAABM9f8DVKdUX8ajF00AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class SimCLRTransform:\n",
    "    def __init__(self, size = 64):\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(size=64, scale = (0.5, 1.0)),\n",
    "            transforms.RandomRotation(180, expand=False),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomApply([\n",
    "                transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)\n",
    "            ], p = 0.8),\n",
    "            transforms.RandomGrayscale(p=0.2),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return self.transform(x), self.transform(x)\n",
    "\n",
    "class SymbolDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.files = glob.glob(os.path.join(root_dir, \"*.jpg\"))\n",
    "        self.transform = SimCLRTransform()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idk):\n",
    "        img_path = self.files[idk]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        return self.transform(img)\n",
    "\n",
    "class SimCLR(nn.Module):\n",
    "    def __init__(self, base_model = \"resnet18\"):\n",
    "        super().__init__()\n",
    "        self.backbone = models.resnet18(weights=None)\n",
    "\n",
    "        dim_mlp = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Identity()\n",
    "\n",
    "        # add the projection head (MLP)\n",
    "        # this is thrown away from training\n",
    "        self.projection_head = nn.Sequential(\n",
    "            nn.Linear(dim_mlp, dim_mlp),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dim_mlp, EMBED_DIM)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        embeddings = self.projection_head(features)\n",
    "        return embeddings\n",
    "    \n",
    "    @staticmethod\n",
    "    # define NT-Xent (Normalized Temperature-Scaled Cross-Entropy)\n",
    "    def nt_xent_loss(z_i, z_j, temperature):\n",
    "        batch_size = z_i.shape[0]\n",
    "\n",
    "        features = torch.cat([z_i, z_j], dim = 0)\n",
    "\n",
    "        features = torch.nn.functional.normalize(features, dim=1)\n",
    "        similarity_matrix = torch.matmul(features, features.T)\n",
    "\n",
    "        # create labels\n",
    "        labels = torch.cat([\n",
    "            torch.arange(batch_size) + batch_size,\n",
    "            torch.arange(batch_size)\n",
    "        ], dim = 0).to(DEVICE)\n",
    "\n",
    "        # mask out self-similarity by setting a very large value on the diagonal\n",
    "        mask = torch.eye(2 * batch_size).to(DEVICE).bool()\n",
    "\n",
    "        logits = similarity_matrix / temperature\n",
    "        logits = logits.masked_fill(mask, -9e15)\n",
    "\n",
    "        loss = torch.nn.functional.cross_entropy(logits, labels)\n",
    "        return loss\n",
    "\n",
    "def train():\n",
    "    dataset = SymbolDataset(DATA_DIR)\n",
    "    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE , shuffle=True, drop_last=True, num_workers=0)\n",
    "\n",
    "    model = SimCLR().to(DEVICE)\n",
    "    optimizer = optim.Adam(model.parameters(), lr = LR)\n",
    "    plot_loss = []\n",
    "    print(f\"Starting training on {DEVICE} with {len(dataset)} symbols...\")\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        total_loss = 0\n",
    "        running_loss = 0.0\n",
    "        for i, (img_view_1, img_view_2) in enumerate(dataloader):\n",
    "            img_view_1 = img_view_1.to(DEVICE)\n",
    "            img_view_2 = img_view_2.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            z1 = model(img_view_1)\n",
    "            z2 = model(img_view_2)\n",
    "\n",
    "            loss = model.nt_xent_loss(z1, z2, TEMP)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # running_loss += loss.item()\n",
    "            # if (i + 1) % 100 == 0:\n",
    "            #     avg_running_loss = running_loss / 100\n",
    "            #     print(f\"Epoch [{epoch+1}/{EPOCHS}] Step [{i+1}/{len(dataloader)}] \"\n",
    "            #           f\"Loss: {avg_running_loss:.4f}\")\n",
    "            #     running_loss = 0.0\n",
    "        \n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        plot_loss.append(avg_loss)\n",
    "        print(f\"Epoch [{epoch+1}/{EPOCHS}] Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            torch.save(model.backbone.state_dict(), f\"simclr_backbone_epoch_{epoch+1}.pth\")\n",
    "            print(f\"Saved Backbone Checkpoint at epoch {epoch+1}\")\n",
    "    np.save('loss.npy', np.array(plot_loss))\n",
    "    print(\"List saved to loss.npy\")\n",
    "\n",
    "    plt.plot(plot_loss, marker='o', linestyle='-')\n",
    "    plt.savefig('plot_loss.png')\n",
    "    print(\"Plot saved to plot_output.png\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "666443f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from pdf2image import convert_from_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce385fa0",
   "metadata": {},
   "source": [
    "## Convert pdf to high-quality image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0264be7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\m6moraxu\\AppData\\Local\\anaconda3\\envs\\dgtwinV2\\lib\\site-packages\\PIL\\Image.py:3167: DecompressionBombWarning: Image size (155520000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "image = convert_from_path(\"./test/landscaping-drawing.pdf\", dpi = 300)\n",
    "image[0].save(\"./test/drawing.png\", \"PNG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "033bab83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Number of available GPUs: 3\n",
      "Current GPU device name: NVIDIA RTX A6000\n",
      "loading model...\n",
      "loading drawing: ./test/drawing.png\n",
      "Image Size: 14400x10800\n",
      "batch scanning document (this may take a while)...\n",
      "Done! Found 214 matches.\n",
      "saved results to results.jpg\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = \"./simclr_backbone_epoch_200.pth\" # The file you just trained\n",
    "DRAWING_PATH = \"./test/drawing.png\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"Using device: {device}\")\n",
    "    print(f\"Number of available GPUs: {torch.cuda.device_count()}\")\n",
    "    print(f\"Current GPU device name: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "WINDOW_SIZE = 600\n",
    "MODEL_INPUT_SIZE = 64\n",
    "STRIDE = 150\n",
    "MATCH_THRESHOLD = 0.98\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "def load_backbone(path):\n",
    "    backbone = models.resnet18(weights=None)\n",
    "    backbone.fc = nn.Identity()\n",
    "\n",
    "    state_dict = torch.load(path, map_location = DEVICE)\n",
    "    backbone.load_state_dict(state_dict)\n",
    "\n",
    "    backbone.to(DEVICE)\n",
    "    backbone.eval()\n",
    "    return backbone\n",
    "\n",
    "def preprocess_batch(crop_list):\n",
    "    batch_up = np.stack(crop_list)\n",
    "    batch_tensor = torch.from_numpy(batch_up).to(DEVICE)\n",
    "    batch_tensor = batch_tensor.permute(0,3,1,2)\n",
    "\n",
    "    batch_tensor = batch_tensor.float() / 255.0\n",
    "\n",
    "    return batch_tensor\n",
    "\n",
    "    \n",
    "\n",
    "def find_symbols():\n",
    "    \n",
    "    print(\"loading model...\")\n",
    "    model = load_backbone(MODEL_PATH)\n",
    "\n",
    "    print(f\"loading drawing: {DRAWING_PATH}\")\n",
    "    full_image = cv2.imread(DRAWING_PATH)\n",
    "    if full_image is None:\n",
    "        print(\"Error: loading image\")\n",
    "        return\n",
    "\n",
    "    full_image = cv2.cvtColor(full_image, cv2.COLOR_BGR2RGB) \n",
    "    H, W, _ = full_image.shape\n",
    "    print(f\"Image Size: {W}x{H}\")\n",
    "\n",
    "    # --- define QUERY (the \"1-shot\") ---\n",
    "    # ideally, the user'd use a mouse click. Here, I mimic by hardcoding a crop location\n",
    "    qx, qy = 7030, 4780\n",
    "    query_crop_huge = full_image[qy:qy+WINDOW_SIZE, qx:qx+WINDOW_SIZE]\n",
    "    query_crop_small = cv2.resize(query_crop_huge, (MODEL_INPUT_SIZE, MODEL_INPUT_SIZE))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        q_tensor = preprocess_batch([query_crop_small])\n",
    "        query_emb = model(q_tensor) # Shape: (1, 512)\n",
    "    \n",
    "\n",
    "    print(\"batch scanning document (this may take a while)...\")\n",
    "\n",
    "    results = []\n",
    "    batch_crops = []\n",
    "    batch_coords = []\n",
    "    \n",
    "\n",
    "    for y in range(0, H - WINDOW_SIZE, STRIDE):\n",
    "        for x in range(0, W - WINDOW_SIZE, STRIDE):\n",
    "\n",
    "            crop_huge = full_image[y:y+WINDOW_SIZE, x:x+WINDOW_SIZE]\n",
    "\n",
    "            # skip areas where the crop is almost white\n",
    "            if crop_huge.mean() > 240:\n",
    "                continue\n",
    "            \n",
    "            crop_small = cv2.resize(crop_huge, (MODEL_INPUT_SIZE, MODEL_INPUT_SIZE))\n",
    "            batch_crops.append(crop_small)\n",
    "            batch_coords.append((x,y))\n",
    "\n",
    "            if len(batch_crops) == BATCH_SIZE:\n",
    "                with torch.no_grad():\n",
    "                    batch_tensor = preprocess_batch(batch_crops)\n",
    "\n",
    "                    batch_embs = model(batch_tensor)\n",
    "\n",
    "                    # output: (1, batch_size)\n",
    "                    scores = torch.nn.functional.cosine_similarity(query_emb, batch_embs)\n",
    "                    mask = scores > MATCH_THRESHOLD\n",
    "\n",
    "                    indices = torch.nonzero(mask).squeeze()\n",
    "\n",
    "                    if indices.numel() > 0:\n",
    "                        # handle the case when \"torch.nonzero(mask)\"\n",
    "                        # returns a single element, then squeeze() will\n",
    "                        # give you a scalar wrapped in a scalar box, shape is [] \n",
    "                        if indices.dim() == 0: indices = indices.unsqueeze(0)\n",
    "                        \n",
    "                        # accumulate results per batch\n",
    "                        for idx in indices:\n",
    "                            idx = idx.item()\n",
    "                            score = scores[idx].item()\n",
    "                            match_x, match_y = batch_coords[idx]\n",
    "                            results.append((match_x, match_y, score))\n",
    "                # Reset Buffer\n",
    "                batch_crops = []\n",
    "                batch_coords = []\n",
    "\n",
    "    # process leftovers\n",
    "    if len(batch_crops) > 0:\n",
    "        with torch.no_grad():\n",
    "            batch_tensor = preprocess_batch(batch_crops)\n",
    "            batch_embs = model(batch_tensor)\n",
    "            scores = torch.nn.functional.cosine_similarity(query_emb, batch_embs)\n",
    "            mask = scores > MATCH_THRESHOLD\n",
    "            indices = torch.nonzero(mask).squeeze()\n",
    "            if indices.numel() > 0:\n",
    "                if indices.dim() == 0: indices = indices.unsqueeze(0)\n",
    "                for idx in indices:\n",
    "                    idx = idx.item()\n",
    "                    score = scores[idx].item()\n",
    "                    match_x, match_y = batch_coords[idx]\n",
    "                    results.append((match_x, match_y, score))\n",
    "    \n",
    "    print(f\"Done! Found {len(results)} matches.\")\n",
    "\n",
    "    # ---visualize---\n",
    "    # Convert back to BGR for OpenCV saving\n",
    "    output_img = cv2.cvtColor(full_image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    # query box (blue)\n",
    "    cv2.rectangle(output_img, (qx, qy), (qx+WINDOW_SIZE, qy+WINDOW_SIZE), (255, 0,0), 3)\n",
    "\n",
    "    # potential matches (green)\n",
    "    for (mx, my, score) in results:\n",
    "        cv2.rectangle(output_img, (mx, my), (mx+WINDOW_SIZE, my+WINDOW_SIZE), (0, 255, 0), 2)\n",
    "\n",
    "    # save results\n",
    "    cv2.imwrite(\"./test/results.jpg\", output_img)\n",
    "    print(\"saved results to results.jpg\") \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    find_symbols()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dgtwinV2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
